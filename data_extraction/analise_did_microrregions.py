#!/usr/bin/env python3
"""
Dataset de Microrregi√µes Brasileiras para An√°lise

Extra√ß√£o com mapeamento CORRETO de microrregi√µes

Este script extrai dados da Base dos Dados usando o mapeamento correto 
munic√≠pio ‚Üí microrregi√£o, gerando um dataset consolidado para an√°lises econom√©tricas.

FONTES DE DADOS:
- √ÅREAS: MapBiomas (√°rea plantada + √°rea total)
- VALOR AGR√çCOLA: PAM/IBGE (apenas valor agregado)
- POPULA√á√ÉO E PIB: IBGE
- TRATAMENTO: Esta√ß√µes INMET

Como usar:
----------
Um √∫nico produto:
    PRODUTOS_AGRICOLAS = ['Soja']

M√∫ltiplos produtos (agregados):
    PRODUTOS_AGRICOLAS = ['Milho', 'Soja']  # An√°lise conjunta

Exemplos de produtos dispon√≠veis (com MapBiomas):
- ['Cana-de-a√ß√∫car'] - Padr√£o
- ['Soja'] - Apenas soja
- ['Arroz'] - Arroz

NOTA: Apenas produtos com mapeamento MapBiomas s√£o suportados.
"""

import basedosdados as bd
import pandas as pd
import os
import json
from itertools import product


# =============================================================================
# CONFIGURA√á√ÉO
# =============================================================================

PROJECT_ID = "bdsdasd"
ANOS = list(range(2003, 2022))

# CONFIGURA√á√ÉO DOS PRODUTOS AGR√çCOLAS
# Pode ser uma lista com 1 ou mais produtos!
# IMPORTANTE: Usar nomes EXATOS conforme PAM/IBGE
PRODUTOS_AGRICOLAS = ['Cana-de-a√ß√∫car', 'Soja (em gr√£o)', 'Arroz (em casca)']

# Garantir que sempre seja uma lista
if isinstance(PRODUTOS_AGRICOLAS, str):
    PRODUTOS_AGRICOLAS = [PRODUTOS_AGRICOLAS]

# MAPEAMENTO: PAM produto ‚Üí MapBiomas id_classe
MAPEAMENTO_PAM_MAPBIOMAS = {
    'Cana-de-a√ß√∫car': '20',
    'Soja (em gr√£o)': '39',
    'Arroz (em casca)': '40'
}

# MAPEAMENTO: PAM produto ‚Üí nome curto para coluna
MAPEAMENTO_NOME_CURTO = {
    'Cana-de-a√ß√∫car': 'cana',
    'Soja (em gr√£o)': 'soja',
    'Arroz (em casca)': 'arroz'
}

# Validar que todos os produtos t√™m mapeamento MapBiomas
produtos_sem_mapbiomas = [p for p in PRODUTOS_AGRICOLAS if p not in MAPEAMENTO_PAM_MAPBIOMAS]
if produtos_sem_mapbiomas:
    raise ValueError(f"‚ùå Produtos sem mapeamento MapBiomas: {produtos_sem_mapbiomas}\n"
                     f"   Produtos dispon√≠veis: {list(MAPEAMENTO_PAM_MAPBIOMAS.keys())}")

os.makedirs("output", exist_ok=True)

print("‚úÖ Configura√ß√£o completa!")
print(f"üìÖ Per√≠odo: {ANOS[0]}-{ANOS[-1]}")
print(f"üåæ Produtos selecionados: {', '.join(PRODUTOS_AGRICOLAS)}")
print(f"üó∫Ô∏è  MapBiomas classes: {[MAPEAMENTO_PAM_MAPBIOMAS[p] for p in PRODUTOS_AGRICOLAS]}")


# =============================================================================
# 1. MAPEAMENTO MUNIC√çPIO ‚Üí MICRORREGI√ÉO
# =============================================================================

print("\n" + "="*80)
print("1. MAPEAMENTO MUNIC√çPIO ‚Üí MICRORREGI√ÉO")
print("="*80)

query_mapeamento = """
SELECT 
    id_municipio,
    id_microrregiao,
    nome AS nome_municipio,
    sigla_uf
FROM 
    `basedosdados.br_bd_diretorios_brasil.municipio`
"""

print("üó∫Ô∏è Baixando mapeamento munic√≠pio ‚Üí microrregi√£o...")
df_municipios = bd.read_sql(query_mapeamento, billing_project_id=PROJECT_ID)

# Ensure consistent ID types (string) throughout the script
df_municipios['id_municipio'] = df_municipios['id_municipio'].astype(str)
df_municipios['id_microrregiao'] = df_municipios['id_microrregiao'].astype(str)

# Remover munic√≠pios sem mapeamento de microrregi√£o
n_total = len(df_municipios)
df_municipios = df_municipios[df_municipios['id_microrregiao'].notna()].copy()
n_validos = len(df_municipios)

if n_total > n_validos:
    print(f"‚ö†Ô∏è  Removidos {n_total - n_validos} munic√≠pios sem id_microrregiao")

print(f"‚úÖ {len(df_municipios):,} munic√≠pios mapeados")
print(f"‚úÖ {df_municipios['id_microrregiao'].nunique()} microrregi√µes identificadas")

# Validate that microrregi√µes don't cross state boundaries
ufs_por_micro = df_municipios.groupby('id_microrregiao')['sigla_uf'].nunique()
if (ufs_por_micro > 1).any():
    print("‚ö†Ô∏è  WARNING: Some microrregi√µes cross state boundaries!")
    micros_problema = ufs_por_micro[ufs_por_micro > 1].index.tolist()
    print(f"   Microrregi√µes problem√°ticas: {micros_problema}")
else:
    print("‚úÖ Valida√ß√£o: Todas as microrregi√µes est√£o dentro de um √∫nico estado")

print("\nExemplo do mapeamento:")
print(df_municipios.head())


# =============================================================================
# 2. ESTA√á√ïES METEOROL√ìGICAS (TRATAMENTO)
# =============================================================================

print("\n" + "="*80)
print("2. ESTA√á√ïES METEOROL√ìGICAS (TRATAMENTO)")
print("="*80)

query_estacoes = """
SELECT
    e.id_municipio,
    e.id_estacao,
    e.estacao AS nome_estacao,
    EXTRACT(YEAR FROM e.data_fundacao) AS ano_fundacao,
    e.latitude,
    e.longitude
FROM
    `basedosdados.br_inmet_bdmep.estacao` e
WHERE
    e.data_fundacao IS NOT NULL
    AND e.id_municipio IS NOT NULL
"""

print("üå°Ô∏è  Baixando dados de esta√ß√µes...")
df_estacoes_mun = bd.read_sql(query_estacoes, billing_project_id=PROJECT_ID)

# Fazer o JOIN com o mapeamento
df_estacoes_full = df_estacoes_mun.merge(
    df_municipios[['id_municipio', 'id_microrregiao']], 
    on='id_municipio', 
    how='left'
)

# Agregar por microrregi√£o
df_estacoes = df_estacoes_full.groupby('id_microrregiao').agg({
    'ano_fundacao': 'min',
    'id_estacao': 'count'
}).reset_index()

df_estacoes.columns = ['id_microrregiao', 'primeiro_ano_estacao', 'num_estacoes']

print(f"‚úÖ {len(df_estacoes)} microrregi√µes com esta√ß√µes ({len(df_estacoes)/558*100:.1f}% de cobertura)")
print(f"‚úÖ Total: {df_estacoes_full['id_estacao'].nunique()} esta√ß√µes")
print(df_estacoes.head())


# =============================================================================
# 3. POPULA√á√ÉO E PIB
# =============================================================================

print("\n" + "="*80)
print("3. POPULA√á√ÉO E PIB")
print("="*80)

# POPULA√á√ÉO
query_pop = f"""
SELECT
    ano,
    id_municipio,
    populacao
FROM
    `basedosdados.br_ibge_populacao.municipio`
WHERE
    ano BETWEEN {ANOS[0]} AND {ANOS[-1]}
"""

print("üë• Baixando dados de popula√ß√£o...")
df_pop_mun = bd.read_sql(query_pop, billing_project_id=PROJECT_ID)
df_pop_mun['id_municipio'] = df_pop_mun['id_municipio'].astype(str)

# JOIN com mapeamento
df_pop_mapped = df_pop_mun.merge(
    df_municipios[['id_municipio', 'id_microrregiao', 'sigla_uf']],
    on='id_municipio',
    how='left'
)

# Report data loss from mapping
n_sem_mapping_pop = df_pop_mapped['id_microrregiao'].isna().sum()
if n_sem_mapping_pop > 0:
    print(f"‚ö†Ô∏è  {n_sem_mapping_pop} registros de popula√ß√£o sem mapeamento de microrregi√£o (ser√£o descartados)")
    df_pop_mapped = df_pop_mapped[df_pop_mapped['id_microrregiao'].notna()].copy()

# Agregar por microrregi√£o
df_pop = df_pop_mapped.groupby(['ano', 'id_microrregiao', 'sigla_uf'])['populacao'].sum().reset_index()
df_pop.columns = ['ano', 'id_microrregiao', 'uf', 'populacao_total']

print(f"‚úÖ {len(df_pop):,} registros agregados")

# PIB
query_pib = f"""
SELECT
    ano,
    id_municipio,
    pib,
    va_agropecuaria
FROM
    `basedosdados.br_ibge_pib.municipio`
WHERE
    ano BETWEEN {ANOS[0]} AND {ANOS[-1]}
"""

print("\nüí∞ Baixando dados de PIB...")
df_pib_mun = bd.read_sql(query_pib, billing_project_id=PROJECT_ID)
df_pib_mun['id_municipio'] = df_pib_mun['id_municipio'].astype(str)

# JOIN com mapeamento
df_pib_mapped = df_pib_mun.merge(
    df_municipios[['id_municipio', 'id_microrregiao']],
    on='id_municipio',
    how='left'
)

# Report data loss from mapping
n_sem_mapping_pib = df_pib_mapped['id_microrregiao'].isna().sum()
if n_sem_mapping_pib > 0:
    print(f"‚ö†Ô∏è  {n_sem_mapping_pib} registros de PIB sem mapeamento de microrregi√£o (ser√£o descartados)")
    df_pib_mapped = df_pib_mapped[df_pib_mapped['id_microrregiao'].notna()].copy()

# Agregar
df_pib = df_pib_mapped.groupby(['ano', 'id_microrregiao']).agg({
    'pib': 'sum',
    'va_agropecuaria': 'sum'
}).reset_index()

df_pib.columns = ['ano', 'id_microrregiao', 'pib_total', 'pib_agropecuario']

print(f"‚úÖ {len(df_pib):,} registros agregados")


# =============================================================================
# 4. CONSOLIDA√á√ÉO DO DATASET
# =============================================================================

print("\n" + "="*80)
print("4. CONSOLIDA√á√ÉO DO DATASET")
print("="*80)

# Obter lista de todas as microrregi√µes
all_micros = sorted(df_municipios['id_microrregiao'].unique())
print(f"üìä Total de microrregi√µes: {len(all_micros)}")

# Criar painel balanceado
painel = pd.DataFrame(
    list(product(all_micros, ANOS)), 
    columns=['id_microrregiao', 'ano']
)

# Adicionar informa√ß√µes b√°sicas das microrregi√µes
micro_info = df_municipios.groupby('id_microrregiao')['sigla_uf'].first().reset_index()
painel = painel.merge(micro_info, on='id_microrregiao', how='left')

# Adicionar tratamento (esta√ß√µes)
painel = painel.merge(
    df_estacoes[['id_microrregiao', 'primeiro_ano_estacao']], 
    on='id_microrregiao', 
    how='left'
)

painel['primeiro_ano_tratamento'] = painel['primeiro_ano_estacao'].fillna(0).astype(int)
painel['tratado'] = (painel['primeiro_ano_tratamento'] != 0).astype(int)
painel['pos_tratamento'] = (
    (painel['ano'] >= painel['primeiro_ano_tratamento']) & 
    (painel['tratado'] == 1)
).astype(int)

# Adicionar popula√ß√£o
painel = painel.merge(
    df_pop[['ano', 'id_microrregiao', 'populacao_total']], 
    on=['ano', 'id_microrregiao'], 
    how='left'
)

# Adicionar PIB
painel = painel.merge(
    df_pib, 
    on=['ano', 'id_microrregiao'], 
    how='left'
)

# PIB per capita
painel['pib_per_capita'] = (painel['pib_total'] / painel['populacao_total']).round(2)

print(f"\n‚úÖ Painel criado: {len(painel):,} observa√ß√µes")
print(f"üìä Microrregi√µes tratadas: {painel[painel['tratado'] == 1]['id_microrregiao'].nunique()}")
print(f"üìä Microrregi√µes controle: {painel[painel['tratado'] == 0]['id_microrregiao'].nunique()}")


# =============================================================================
# 5. DADOS DE VALOR AGR√çCOLA (PAM) - APENAS VALOR
# =============================================================================

print("\n" + "="*80)
print("5. DADOS DE VALOR AGR√çCOLA (PAM) - APENAS VALOR")
print("="*80)

# Converter lista de produtos para formato SQL
produtos_sql = ', '.join([f"'{p}'" for p in PRODUTOS_AGRICOLAS])

query_pam = f"""
SELECT
    lav.id_municipio,
    lav.ano,
    lav.produto,
    lav.valor_producao
FROM
    `basedosdados.br_ibge_pam.lavoura_temporaria` AS lav
WHERE
    lav.ano BETWEEN {ANOS[0]} AND {ANOS[-1]}
    AND lav.produto IN ({produtos_sql})
"""

print(f"üí∞ Baixando dados de valor de produ√ß√£o de: {', '.join(PRODUTOS_AGRICOLAS)}...")
df_pam_mun = bd.read_sql(query_pam, billing_project_id=PROJECT_ID)
df_pam_mun['id_municipio'] = df_pam_mun['id_municipio'].astype(str)
print(f"‚úÖ {len(df_pam_mun):,} registros de valor municipal")

# JOIN com mapeamento para obter microrregi√£o
df_pam_mapped = df_pam_mun.merge(
    df_municipios[['id_municipio', 'id_microrregiao']],
    on='id_municipio',
    how='left'
)

# Report data loss from mapping
n_sem_mapping_pam = df_pam_mapped['id_microrregiao'].isna().sum()
if n_sem_mapping_pam > 0:
    print(f"‚ö†Ô∏è  {n_sem_mapping_pam} registros de PAM sem mapeamento de microrregi√£o (ser√£o descartados)")
    df_pam_mapped = df_pam_mapped[df_pam_mapped['id_microrregiao'].notna()].copy()

# Agregar por microrregi√£o E produto (manter produtos separados)
df_valor_por_produto = df_pam_mapped.groupby(['ano', 'id_microrregiao', 'produto']).agg({
    'valor_producao': 'sum'
}).reset_index()

# Mapear produto para nome curto
df_valor_por_produto['produto_curto'] = df_valor_por_produto['produto'].map(MAPEAMENTO_NOME_CURTO)

# Check which products have data
produtos_com_dados = df_valor_por_produto['produto'].unique()
produtos_sem_dados = [p for p in PRODUTOS_AGRICOLAS if p not in produtos_com_dados]
if produtos_sem_dados:
    print(f"‚ö†Ô∏è  Produtos sem dados de valor de produ√ß√£o (PAM): {produtos_sem_dados}")

# Pivotar: cada produto vira uma coluna valor_producao_<produto>
df_valor = df_valor_por_produto.pivot_table(
    index=['ano', 'id_microrregiao'],
    columns='produto_curto',
    values='valor_producao',
    fill_value=0
).reset_index()

# Renomear colunas para valor_producao_<produto>
df_valor.columns.name = None  # Remover nome do √≠ndice de colunas
novos_nomes = {col: f'valor_producao_{col}' for col in df_valor.columns if col not in ['ano', 'id_microrregiao']}
df_valor = df_valor.rename(columns=novos_nomes)

# Ensure all expected columns exist (add missing ones with zeros)
for produto in PRODUTOS_AGRICOLAS:
    nome_curto = MAPEAMENTO_NOME_CURTO[produto]
    col_name = f'valor_producao_{nome_curto}'
    if col_name not in df_valor.columns:
        print(f"‚ö†Ô∏è  Criando coluna vazia: {col_name}")
        df_valor[col_name] = 0

print(f"‚úÖ {len(df_valor):,} registros de valor agregados por microrregi√£o")
print(f"‚úÖ Colunas criadas: {sorted([col for col in df_valor.columns if col.startswith('valor_producao_')])}")
for col in sorted([col for col in df_valor.columns if col.startswith('valor_producao_')]):
    n_nonzero = (df_valor[col] > 0).sum()
    if n_nonzero > 0:
        media = df_valor[df_valor[col] > 0][col].mean()
        print(f"   üìä {col}: {n_nonzero} obs com valor > 0, m√©dia = R$ {media:,.0f}")
    else:
        print(f"   üìä {col}: 0 obs com valor > 0 (sem dados PAM)")


# =============================================================================
# 6. DADOS DE USO DO SOLO (MAPBIOMAS)
# =============================================================================

print("\n" + "="*80)
print("6. DADOS DE USO DO SOLO (MAPBIOMAS)")
print("="*80)

# Obter IDs das classes MapBiomas para os produtos selecionados
ids_classes = [MAPEAMENTO_PAM_MAPBIOMAS[p] for p in PRODUTOS_AGRICOLAS]
# id_classe √© STRING no BigQuery, ent√£o precisa de aspas
ids_str = ', '.join([f"'{id_classe}'" for id_classe in ids_classes])

# Criar mapeamento reverso: id_classe ‚Üí nome_curto
id_classe_para_nome = {MAPEAMENTO_PAM_MAPBIOMAS[p]: MAPEAMENTO_NOME_CURTO[p] for p in PRODUTOS_AGRICOLAS}

print(f"üó∫Ô∏è  Classes MapBiomas: {ids_str}")
print(f"üó∫Ô∏è  Mapeamento: {id_classe_para_nome}")

# Query 1: √Årea plantada do(s) produto(s)
query_mapbiomas_plantada = f"""
SELECT
    ano,
    id_municipio,
    id_classe,
    area
FROM 
    `basedosdados.br_mapbiomas_estatisticas.cobertura_municipio_classe`
WHERE 
    ano BETWEEN {ANOS[0]} AND {ANOS[-1]}
    AND id_classe IN ({ids_str})
"""

print("üåæ Baixando √°rea plantada (MapBiomas)...")
df_mapbiomas_mun = bd.read_sql(query_mapbiomas_plantada, billing_project_id=PROJECT_ID)
df_mapbiomas_mun['id_municipio'] = df_mapbiomas_mun['id_municipio'].astype(str)
print(f"‚úÖ {len(df_mapbiomas_mun):,} registros municipais de √°rea plantada")

# JOIN com mapeamento
df_mapbiomas_mapped = df_mapbiomas_mun.merge(
    df_municipios[['id_municipio', 'id_microrregiao']],
    on='id_municipio',
    how='left'
)

# Report data loss from mapping
n_sem_mapping_mapbiomas = df_mapbiomas_mapped['id_microrregiao'].isna().sum()
if n_sem_mapping_mapbiomas > 0:
    print(f"‚ö†Ô∏è  {n_sem_mapping_mapbiomas} registros de MapBiomas sem mapeamento de microrregi√£o (ser√£o descartados)")
    df_mapbiomas_mapped = df_mapbiomas_mapped[df_mapbiomas_mapped['id_microrregiao'].notna()].copy()

# Agregar por microrregi√£o E id_classe (manter produtos separados)
df_area_por_classe = df_mapbiomas_mapped.groupby(['ano', 'id_microrregiao', 'id_classe']).agg({
    'area': 'sum'
}).reset_index()

# Mapear id_classe para nome do produto
df_area_por_classe['produto'] = df_area_por_classe['id_classe'].astype(str).map(id_classe_para_nome)

# Pivotar: cada produto vira uma coluna area_plantada_<produto>
df_area_plantada = df_area_por_classe.pivot_table(
    index=['ano', 'id_microrregiao'],
    columns='produto',
    values='area',
    fill_value=0
).reset_index()

# Renomear colunas para area_plantada_<produto>
df_area_plantada.columns.name = None  # Remover nome do √≠ndice de colunas
novos_nomes = {col: f'area_plantada_{col}' for col in df_area_plantada.columns if col not in ['ano', 'id_microrregiao']}
df_area_plantada = df_area_plantada.rename(columns=novos_nomes)

print(f"‚úÖ {len(df_area_plantada):,} registros de √°rea plantada por microrregi√£o")
print(f"‚úÖ Colunas criadas: {[col for col in df_area_plantada.columns if col.startswith('area_plantada_')]}")
for col in df_area_plantada.columns:
    if col.startswith('area_plantada_'):
        media = df_area_plantada[df_area_plantada[col] > 0][col].mean()
        print(f"   üìä {col}: m√©dia = {media:,.1f} km¬≤")

# Query 2: √Årea total por munic√≠pio
query_area_total = f"""
SELECT
    ano,
    id_municipio,
    SUM(area) as area_total_km2
FROM 
    `basedosdados.br_mapbiomas_estatisticas.cobertura_municipio_classe`
WHERE 
    ano BETWEEN {ANOS[0]} AND {ANOS[-1]}
GROUP BY 
    ano, id_municipio
"""

print("\nüåç Baixando √°rea total (MapBiomas)...")
df_area_total_mun = bd.read_sql(query_area_total, billing_project_id=PROJECT_ID)
df_area_total_mun['id_municipio'] = df_area_total_mun['id_municipio'].astype(str)
print(f"‚úÖ {len(df_area_total_mun):,} registros municipais de √°rea total")

# JOIN com mapeamento
df_area_total_mapped = df_area_total_mun.merge(
    df_municipios[['id_municipio', 'id_microrregiao']],
    on='id_municipio',
    how='left'
)

# Report data loss from mapping
n_sem_mapping_area_total = df_area_total_mapped['id_microrregiao'].isna().sum()
if n_sem_mapping_area_total > 0:
    print(f"‚ö†Ô∏è  {n_sem_mapping_area_total} registros de √°rea total sem mapeamento de microrregi√£o (ser√£o descartados)")
    df_area_total_mapped = df_area_total_mapped[df_area_total_mapped['id_microrregiao'].notna()].copy()

# Agregar por microrregi√£o
df_area_total = df_area_total_mapped.groupby(['ano', 'id_microrregiao']).agg({
    'area_total_km2': 'sum'
}).reset_index()

print(f"‚úÖ {len(df_area_total):,} registros de √°rea total por microrregi√£o")
print(f"üìä √Årea total m√©dia: {df_area_total['area_total_km2'].sum():,.1f} km¬≤")


# =============================================================================
# 7. DADOS DE PRECIPITA√á√ÉO (CDS/ERA5 local)
# =============================================================================

print("\n" + "="*80)
print("7. DADOS DE PRECIPITA√á√ÉO (CDS/ERA5 local)")
print("="*80)

# Ler CSV local de precipita√ß√£o
precip_path = 'CDS/precipitacao_municipal_anual_com_centroides.csv'
print(f"üåßÔ∏è  Carregando dados de precipita√ß√£o: {precip_path}")
df_precip_mun = pd.read_csv(precip_path)

# Renomear CD_MUN para id_municipio para compatibilidade
df_precip_mun = df_precip_mun.rename(columns={'CD_MUN': 'id_municipio'})

# Garantir que id_municipio √© do mesmo tipo que no mapeamento
df_precip_mun['id_municipio'] = df_precip_mun['id_municipio'].astype(str)

# Selecionar apenas as colunas necess√°rias (ano, id_municipio, e as tr√™s vari√°veis "_mm")
colunas_precip = ['id_municipio', 'ano', 'precip_total_anual_mm', 'precip_media_mensal_mm', 'precip_max_mensal_mm']
df_precip_clean = df_precip_mun[colunas_precip].copy()

print(f"‚úÖ {len(df_precip_clean):,} registros municipais de precipita√ß√£o")
print(f"üìä Anos dispon√≠veis: {sorted(df_precip_clean['ano'].unique())}")

# JOIN com mapeamento munic√≠pio ‚Üí microrregi√£o
df_precip_mapped = df_precip_clean.merge(
    df_municipios[['id_municipio', 'id_microrregiao']], 
    on='id_municipio', 
    how='left'
)

# Verificar cobertura do mapeamento
n_sem_micro = df_precip_mapped['id_microrregiao'].isna().sum()
if n_sem_micro > 0:
    print(f"‚ö†Ô∏è  {n_sem_micro} registros de precipita√ß√£o sem mapeamento de microrregi√£o (ser√£o descartados)")
    df_precip_mapped = df_precip_mapped[df_precip_mapped['id_microrregiao'].notna()].copy()

# Agregar precipita√ß√£o por microrregi√£o-ano
# Regra de agrega√ß√£o:
#   - precip_total_anual_mm: soma (total acumulado da microrregi√£o)
#   - precip_media_mensal_mm: m√©dia (m√©dia das m√©dias municipais)
#   - precip_max_mensal_mm: m√©dia (m√©dia dos m√°ximos municipais)
df_precip = df_precip_mapped.groupby(['ano', 'id_microrregiao']).agg({
    'precip_total_anual_mm': 'sum',
    'precip_media_mensal_mm': 'mean',
    'precip_max_mensal_mm': 'mean'
}).reset_index()

print(f"‚úÖ {len(df_precip):,} registros de precipita√ß√£o agregados por microrregi√£o")
print(f"üìä Precipita√ß√£o total anual m√©dia: {df_precip['precip_total_anual_mm'].mean():,.1f} mm")
print(f"üìä Precipita√ß√£o m√©dia mensal m√©dia: {df_precip['precip_media_mensal_mm'].mean():,.1f} mm")
print(f"üìä Precipita√ß√£o m√°xima mensal m√©dia: {df_precip['precip_max_mensal_mm'].mean():,.1f} mm")


# =============================================================================
# 8. CONSOLIDA√á√ÉO FINAL DO PAINEL
# =============================================================================

print("\n" + "="*80)
print("8. CONSOLIDA√á√ÉO FINAL DO PAINEL")
print("="*80)

# Come√ßar com o painel base
painel_final = painel.copy()

# Remover coluna auxiliar se existir
if 'primeiro_ano_estacao' in painel_final.columns:
    painel_final = painel_final.drop('primeiro_ano_estacao', axis=1)

# Adicionar valor agregado (PAM)
painel_final = painel_final.merge(
    df_valor, 
    on=['ano', 'id_microrregiao'], 
    how='left'
)

# Adicionar √°rea plantada (MapBiomas)
painel_final = painel_final.merge(
    df_area_plantada, 
    on=['ano', 'id_microrregiao'], 
    how='left'
)

# Adicionar √°rea total (MapBiomas)
painel_final = painel_final.merge(
    df_area_total, 
    on=['ano', 'id_microrregiao'], 
    how='left'
)

# Adicionar precipita√ß√£o (CDS/ERA5)
painel_final = painel_final.merge(
    df_precip, 
    on=['ano', 'id_microrregiao'], 
    how='left'
)

# Preencher zeros onde n√£o h√° dados
colunas_area_plantada = [col for col in painel_final.columns if col.startswith('area_plantada_')]
colunas_valor_producao = [col for col in painel_final.columns if col.startswith('valor_producao_')]

painel_final['area_total_km2'] = painel_final['area_total_km2'].fillna(0)

# Preencher zeros para todas as colunas de √°rea plantada por produto
for col in colunas_area_plantada:
    painel_final[col] = painel_final[col].fillna(0)

# Preencher zeros para todas as colunas de valor de produ√ß√£o por produto
for col in colunas_valor_producao:
    painel_final[col] = painel_final[col].fillna(0)

# Fill precipitation with 0 as well for consistency
painel_final['precip_total_anual_mm'] = painel_final['precip_total_anual_mm'].fillna(0)
painel_final['precip_media_mensal_mm'] = painel_final['precip_media_mensal_mm'].fillna(0)
painel_final['precip_max_mensal_mm'] = painel_final['precip_max_mensal_mm'].fillna(0)

# Validate balanced panel
n_esperado = len(all_micros) * len(ANOS)
n_observado = len(painel_final)
if n_esperado != n_observado:
    print(f"\n‚ö†Ô∏è  WARNING: Panel is not balanced!")
    print(f"   Esperado: {n_esperado:,} observa√ß√µes ({len(all_micros)} micros √ó {len(ANOS)} anos)")
    print(f"   Observado: {n_observado:,} observa√ß√µes")
    print(f"   Diferen√ßa: {n_esperado - n_observado:,} observa√ß√µes faltando")
else:
    print(f"\n‚úÖ Valida√ß√£o: Painel balanceado ({n_observado:,} observa√ß√µes)")

# Filter out microrregi√µes with ZERO agricultural activity across ALL years
# Keep microrregi√µes that have EITHER MapBiomas area data OR PAM production value data
print("\n" + "="*80)
print("FILTRO: Removendo microrregi√µes sem produ√ß√£o agr√≠cola")
print("="*80)
print(f"üìä Tamanho antes do filtro: {len(painel_final):,} observa√ß√µes")
print(f"üìä Microrregi√µes antes: {painel_final['id_microrregiao'].nunique()}")

# Calculate total planted area per microrregi√£o across all years and crops (MapBiomas)
colunas_area_plantada = [col for col in painel_final.columns if col.startswith('area_plantada_')]
painel_final['area_total_produtos'] = painel_final[colunas_area_plantada].sum(axis=1)

# Calculate total production value per microrregi√£o across all years and crops (PAM)
colunas_valor_producao = [col for col in painel_final.columns if col.startswith('valor_producao_')]
painel_final['valor_total_produtos'] = painel_final[colunas_valor_producao].sum(axis=1)

# Identify microrregi√µes with at least SOME area OR value in at least ONE year
micros_com_area = painel_final.groupby('id_microrregiao')['area_total_produtos'].sum()
micros_com_area = set(micros_com_area[micros_com_area > 0].index)

micros_com_valor = painel_final.groupby('id_microrregiao')['valor_total_produtos'].sum()
micros_com_valor = set(micros_com_valor[micros_com_valor > 0].index)

# Union: keep microrregi√µes with EITHER area OR value
micros_com_producao = micros_com_area.union(micros_com_valor)

print(f"   - Microrregi√µes com MapBiomas √°rea > 0: {len(micros_com_area)}")
print(f"   - Microrregi√µes com PAM valor > 0: {len(micros_com_valor)}")
print(f"   - Total com √°rea OU valor: {len(micros_com_producao)}")

# Filter the panel
n_micros_antes = painel_final['id_microrregiao'].nunique()
painel_final = painel_final[painel_final['id_microrregiao'].isin(micros_com_producao)].copy()
n_micros_depois = painel_final['id_microrregiao'].nunique()

# Drop the auxiliary columns
painel_final = painel_final.drop(['area_total_produtos', 'valor_total_produtos'], axis=1)

print(f"‚úÖ Tamanho ap√≥s filtro: {len(painel_final):,} observa√ß√µes")
print(f"‚úÖ Microrregi√µes ap√≥s filtro: {n_micros_depois}")
print(f"‚úÖ Microrregi√µes removidas: {n_micros_antes - n_micros_depois} ({(n_micros_antes - n_micros_depois)/n_micros_antes*100:.1f}%)")
print(f"‚úÖ Microrregi√µes tratadas ap√≥s filtro: {painel_final[painel_final['tratado'] == 1]['id_microrregiao'].nunique()}")
print(f"‚úÖ Microrregi√µes controle ap√≥s filtro: {painel_final[painel_final['tratado'] == 0]['id_microrregiao'].nunique()}")

# Estat√≠sticas do painel final
print("\n" + "="*80)
print("ESTAT√çSTICAS DO PAINEL FINAL")
print("="*80)
print(f"üìä Total de observa√ß√µes: {len(painel_final):,}")
print(f"üìä √Årea total m√©dia: {painel_final['area_total_km2'].mean():,.1f} km¬≤")
print("\nüìä √Åreas plantadas por produto:")
for col in colunas_area_plantada:
    n_obs = (painel_final[col] > 0).sum()
    pct = n_obs / len(painel_final) * 100
    n_micros = painel_final[painel_final[col] > 0]['id_microrregiao'].nunique()
    media = painel_final[painel_final[col] > 0][col].mean() if n_obs > 0 else 0
    print(f"   - {col}: {n_obs} obs ({pct:.1f}%), {n_micros} microrregi√µes, m√©dia = {media:,.1f} km¬≤")
print("\nüìä Valor de produ√ß√£o por produto:")
for col in colunas_valor_producao:
    n_obs = (painel_final[col] > 0).sum()
    pct = n_obs / len(painel_final) * 100
    n_micros = painel_final[painel_final[col] > 0]['id_microrregiao'].nunique()
    media = painel_final[painel_final[col] > 0][col].mean() if n_obs > 0 else 0
    print(f"   - {col}: {n_obs} obs ({pct:.1f}%), {n_micros} microrregi√µes, m√©dia = R$ {media:,.0f}")


# =============================================================================
# 9. EXPORTAR DATASET FINAL
# =============================================================================

print("\n" + "="*80)
print("9. EXPORTAR DATASET FINAL")
print("="*80)

# Ordenar colunas (apenas vari√°veis do novo pipeline)
# Primeiro as colunas fixas
cols_order = [
    'ano', 'id_microrregiao', 'sigla_uf',
    'primeiro_ano_tratamento', 'tratado', 'pos_tratamento'
]

# Adicionar todas as colunas area_plantada_<produto> dinamicamente
colunas_area_plantada = sorted([col for col in painel_final.columns if col.startswith('area_plantada_')])
cols_order.extend(colunas_area_plantada)

# Adicionar todas as colunas valor_producao_<produto> dinamicamente
colunas_valor_producao = sorted([col for col in painel_final.columns if col.startswith('valor_producao_')])
cols_order.extend(colunas_valor_producao)

# Adicionar restante das colunas
cols_order.extend([
    'area_total_km2',
    'populacao_total', 'pib_total', 'pib_per_capita', 'pib_agropecuario',
    'precip_total_anual_mm', 'precip_media_mensal_mm', 'precip_max_mensal_mm'
])

# Selecionar colunas existentes
cols_final = [c for c in cols_order if c in painel_final.columns]
df_final = painel_final[cols_final].sort_values(['id_microrregiao', 'ano'])

# Criar nome do arquivo com produtos separados por h√≠fen
# Remover sufixos "(em gr√£o)" e "(em casca)" dos nomes para o arquivo
produtos_filename_list = []
for p in PRODUTOS_AGRICOLAS:
    # Remove "(em gr√£o)" e "(em casca)" para manter compatibilidade com nomes antigos
    nome_limpo = p.replace(' (em gr√£o)', '').replace(' (em casca)', '')
    produtos_filename_list.append(nome_limpo)
produtos_filename = '-'.join(produtos_filename_list)
output_file = f'data/microrregions_{produtos_filename}_{min(ANOS)}-{max(ANOS)}_mapbiomas.csv'

# Criar diret√≥rio se n√£o existir
os.makedirs('data', exist_ok=True)

# Salvar com nome descritivo
df_final.to_csv(output_file, index=False)

print(f"‚úÖ Dataset exportado: {output_file}")
print(f"üìè Tamanho: {os.path.getsize(output_file) / 1024 / 1024:.1f} MB")
print(f"üìä Dimens√µes: {len(df_final):,} observa√ß√µes √ó {len(df_final.columns)} vari√°veis")


# =============================================================================
# 10. GERAR DICION√ÅRIO DE VARI√ÅVEIS (DATA DICTIONARY)
# =============================================================================

print("\n" + "="*80)
print("10. GERAR DICION√ÅRIO DE VARI√ÅVEIS")
print("="*80)

def infer_variable_type(series):
    """
    Infer a coarse data type from a pandas Series.
    Returns: 'integer', 'float', 'boolean', 'category', or 'string'
    """
    dtype = series.dtype
    
    if pd.api.types.is_integer_dtype(dtype):
        return 'integer'
    elif pd.api.types.is_float_dtype(dtype):
        return 'float'
    elif pd.api.types.is_bool_dtype(dtype):
        return 'boolean'
    elif pd.api.types.is_categorical_dtype(dtype):
        return 'category'
    elif pd.api.types.is_object_dtype(dtype):
        # Could be string or mixed
        return 'string'
    else:
        return 'string'


def compute_stats(series, var_type):
    """
    Compute univariate statistics for a variable based on its type.
    """
    stats = {
        'n': int(series.notna().sum()),
        'n_missing': int(series.isna().sum())
    }
    
    if var_type in ['integer', 'float']:
        # Numeric statistics
        if stats['n'] > 0:
            stats['mean'] = float(series.mean()) if pd.notna(series.mean()) else None
            stats['std'] = float(series.std()) if pd.notna(series.std()) else None
            stats['min'] = float(series.min()) if pd.notna(series.min()) else None
            stats['max'] = float(series.max()) if pd.notna(series.max()) else None
            stats['median'] = float(series.median()) if pd.notna(series.median()) else None
            stats['q25'] = float(series.quantile(0.25)) if pd.notna(series.quantile(0.25)) else None
            stats['q75'] = float(series.quantile(0.75)) if pd.notna(series.quantile(0.75)) else None
        else:
            stats['mean'] = None
            stats['std'] = None
            stats['min'] = None
            stats['max'] = None
            stats['median'] = None
            stats['q25'] = None
            stats['q75'] = None
    else:
        # Non-numeric statistics
        stats['n_unique'] = int(series.nunique())
        
        # Top categories (most frequent values)
        if stats['n'] > 0:
            value_counts = series.value_counts().head(10)
            stats['top_values'] = [
                {'value': str(val), 'count': int(count)}
                for val, count in value_counts.items()
            ]
        else:
            stats['top_values'] = []
    
    return stats


# Metadata mapping for known variables
# This provides human-readable labels, sources, and units
VARIABLE_METADATA = {
    # Identifiers
    'ano': {
        'label': 'Calendar year',
        'source': 'constructed',
        'units': 'year',
        'notes': 'Panel time dimension'
    },
    'id_microrregiao': {
        'label': 'IBGE microrregi√£o code',
        'source': 'IBGE Diret√≥rios Brasil',
        'units': None,
        'notes': 'Panel cross-sectional unit identifier'
    },
    'sigla_uf': {
        'label': 'State abbreviation (UF)',
        'source': 'IBGE Diret√≥rios Brasil',
        'units': None,
        'notes': 'Two-letter state code'
    },
    
    # Treatment variables
    'primeiro_ano_tratamento': {
        'label': 'Year of first INMET station installation',
        'source': 'INMET',
        'units': 'year',
        'notes': 'Zero if no station installed; minimum foundation year across all stations in the microrregi√£o'
    },
    'tratado': {
        'label': 'Treatment group indicator',
        'source': 'constructed',
        'units': None,
        'notes': '1 if microrregi√£o ever receives a meteorological station, 0 otherwise'
    },
    'pos_tratamento': {
        'label': 'Post-treatment indicator',
        'source': 'constructed',
        'units': None,
        'notes': '1 if year >= first treatment year and microrregi√£o is treated, 0 otherwise'
    },
    
    # Area variables (MapBiomas)
    'area_total_km2': {
        'label': 'Total land area',
        'source': 'MapBiomas cobertura_municipio_classe',
        'units': 'km¬≤',
        'notes': 'Total area across all land cover classes'
    },
    
    # Population and economic variables
    'populacao_total': {
        'label': 'Total population',
        'source': 'IBGE Popula√ß√£o',
        'units': 'persons',
        'notes': 'Aggregated municipal population'
    },
    'pib_total': {
        'label': 'Total GDP',
        'source': 'IBGE PIB',
        'units': 'BRL (nominal, 1000s)',
        'notes': 'Gross domestic product at current prices'
    },
    'pib_per_capita': {
        'label': 'GDP per capita',
        'source': 'constructed',
        'units': 'BRL per person (nominal)',
        'notes': 'Computed as pib_total / populacao_total'
    },
    'pib_agropecuario': {
        'label': 'Agricultural GDP',
        'source': 'IBGE PIB',
        'units': 'BRL (nominal, 1000s)',
        'notes': 'Value added from agricultural and livestock activities'
    },
    
    # Precipitation variables
    'precip_total_anual_mm': {
        'label': 'Total annual precipitation',
        'source': 'CDS/ERA5 local CSV',
        'units': 'mm',
        'notes': 'Sum of municipal precipitation totals within microrregi√£o'
    },
    'precip_media_mensal_mm': {
        'label': 'Mean monthly precipitation',
        'source': 'CDS/ERA5 local CSV',
        'units': 'mm',
        'notes': 'Average of municipal mean monthly precipitation'
    },
    'precip_max_mensal_mm': {
        'label': 'Maximum monthly precipitation',
        'source': 'CDS/ERA5 local CSV',
        'units': 'mm',
        'notes': 'Average of municipal maximum monthly precipitation'
    }
}

# Add metadata for dynamic area_plantada_<produto> columns
for produto in PRODUTOS_AGRICOLAS:
    nome_curto = MAPEAMENTO_NOME_CURTO[produto]
    col_name = f'area_plantada_{nome_curto}'
    id_classe = MAPEAMENTO_PAM_MAPBIOMAS[produto]

    VARIABLE_METADATA[col_name] = {
        'label': f'Planted area of {produto}',
        'source': 'MapBiomas cobertura_municipio_classe',
        'units': 'km¬≤',
        'notes': f'MapBiomas class {id_classe}; aggregated from municipal to microrregi√£o level'
    }

# Add metadata for dynamic valor_producao_<produto> columns
for produto in PRODUTOS_AGRICOLAS:
    nome_curto = MAPEAMENTO_NOME_CURTO[produto]
    col_name = f'valor_producao_{nome_curto}'

    VARIABLE_METADATA[col_name] = {
        'label': f'Production value of {produto}',
        'source': 'PAM/IBGE lavoura_temporaria',
        'units': 'BRL (nominal)',
        'notes': f'Sum of production value for {produto}; aggregated from municipal to microrregi√£o level'
    }


# Build the data dictionary
data_dictionary = {}

print(f"üîç Processando {len(df_final.columns)} vari√°veis...")

for col in df_final.columns:
    # Infer type
    var_type = infer_variable_type(df_final[col])
    
    # Compute statistics
    stats = compute_stats(df_final[col], var_type)
    
    # Get metadata (use mapping or generate generic metadata)
    if col in VARIABLE_METADATA:
        meta = VARIABLE_METADATA[col].copy()
        label = meta.pop('label')
        source = meta.pop('source')
        units = meta.pop('units')
        notes = meta.pop('notes', None)
    else:
        # Fallback for unmapped variables
        label = f"Variable: {col}"
        source = "unknown"
        units = None
        notes = "Metadata not explicitly defined"
    
    # Build entry
    entry = {
        'label': label,
        'type': var_type,
        'source': source,
        'stats': stats
    }
    
    if units is not None:
        entry['units'] = units
    
    if notes is not None:
        entry['notes'] = notes
    
    data_dictionary[col] = entry

# Generate dictionary filename matching the CSV
dict_file = output_file.replace('.csv', '_dict.json')

# Save to JSON
with open(dict_file, 'w', encoding='utf-8') as f:
    json.dump(data_dictionary, f, indent=2, ensure_ascii=False)

print(f"‚úÖ Dicion√°rio de vari√°veis exportado: {dict_file}")
print(f"üìè Tamanho: {os.path.getsize(dict_file) / 1024:.1f} KB")
print(f"üìä Vari√°veis documentadas: {len(data_dictionary)}")

# Print summary by source
print("\nüìã Distribui√ß√£o das vari√°veis por fonte:")
sources = {}
for var, meta in data_dictionary.items():
    src = meta['source']
    sources[src] = sources.get(src, 0) + 1

for src, count in sorted(sources.items(), key=lambda x: x[1], reverse=True):
    print(f"   - {src}: {count} vari√°veis")

# Estat√≠sticas finais
print("\nüìä Resumo do dataset final:")
print(f"  - Microrregi√µes: {df_final['id_microrregiao'].nunique()}")
print(f"  - Estados: {df_final['sigla_uf'].nunique()}")
print(f"  - Anos: {ANOS[0]}-{ANOS[-1]}")
print(f"  - Microrregi√µes tratadas: {df_final[df_final['tratado'] == 1]['id_microrregiao'].nunique()}")
print(f"  - Microrregi√µes controle: {df_final[df_final['tratado'] == 0]['id_microrregiao'].nunique()}")
print("\nüìä Cobertura de dados:")
print(f"  - √Årea total m√©dia: {df_final['area_total_km2'].mean():,.1f} km¬≤")
print("\nüìä √Åreas plantadas por produto (dataset final):")
colunas_area_final = [col for col in df_final.columns if col.startswith('area_plantada_')]
for col in colunas_area_final:
    n_obs = (df_final[col] > 0).sum()
    pct = n_obs / len(df_final) * 100
    media = df_final[df_final[col] > 0][col].mean() if n_obs > 0 else 0
    print(f"  - {col}: {n_obs} obs ({pct:.1f}%), m√©dia = {media:,.1f} km¬≤")
print("\nüìä Valor de produ√ß√£o por produto (dataset final):")
colunas_valor_final = [col for col in df_final.columns if col.startswith('valor_producao_')]
for col in colunas_valor_final:
    n_obs = (df_final[col] > 0).sum()
    pct = n_obs / len(df_final) * 100
    media = df_final[df_final[col] > 0][col].mean() if n_obs > 0 else 0
    print(f"  - {col}: {n_obs} obs ({pct:.1f}%), m√©dia = R$ {media:,.0f}")
print("\nüìä Missing values:")
print(f"  - Popula√ß√£o: {df_final['populacao_total'].isnull().sum()} ({df_final['populacao_total'].isnull().sum()/len(df_final)*100:.1f}%)")
print(f"  - PIB: {df_final['pib_total'].isnull().sum()} ({df_final['pib_total'].isnull().sum()/len(df_final)*100:.1f}%)")
print(f"  - Precipita√ß√£o total anual: {df_final['precip_total_anual_mm'].isnull().sum()} ({df_final['precip_total_anual_mm'].isnull().sum()/len(df_final)*100:.1f}%)")
print("\nüìä Estat√≠sticas de precipita√ß√£o:")
if df_final['precip_total_anual_mm'].notna().sum() > 0:
    print(f"  - Precipita√ß√£o total anual m√©dia: {df_final['precip_total_anual_mm'].mean():.1f} mm")
    print(f"  - Precipita√ß√£o m√©dia mensal m√©dia: {df_final['precip_media_mensal_mm'].mean():.1f} mm")
    print(f"  - Precipita√ß√£o m√°xima mensal m√©dia: {df_final['precip_max_mensal_mm'].mean():.1f} mm")

# Salvar mapeamento munic√≠pio-microrregi√£o
df_municipios.to_csv('output/mapeamento_municipio_microrregiao.csv', index=False)
print("\n‚úÖ Mapeamento salvo: output/mapeamento_municipio_microrregiao.csv")

# Mostrar amostra final
print("\nüìã Amostra do dataset final:")
print(df_final.head(10))

print("\n" + "="*80)
print("‚ú® PROCESSAMENTO CONCLU√çDO COM SUCESSO!")
print("üì¶ Dados: MapBiomas (√°rea) + PAM (valor) + IBGE (PIB/pop) + INMET (tratamento) + CDS/ERA5 (precipita√ß√£o)")
print(f"üìñ Dicion√°rio de vari√°veis salvo em: {dict_file}")
print("="*80)