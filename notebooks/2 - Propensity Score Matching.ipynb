{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Propensity Score Matching\n",
    "\n",
    "**Author:** Daniel Cavalli <br>\n",
    "**Last Update:** 2024-11-08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_for_psm(df):\n",
    "    \"\"\"\n",
    "    Prepare data by handling missing values and creating features\n",
    "    \"\"\"\n",
    "    # Create lists of column names by type\n",
    "    precip_cols = [col for col in df.columns if 'precipitacao' in col]\n",
    "    pressao_cols = [col for col in df.columns if 'pressao' in col]\n",
    "    temp_cols = [col for col in df.columns if 'temperatura' in col]\n",
    "    umidade_cols = [col for col in df.columns if 'umidade' in col]\n",
    "    vento_cols = [col for col in df.columns if 'vento' in col]\n",
    "    \n",
    "    # Create imputer\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    \n",
    "    # Create copy of dataframe\n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    # Impute missing values for each group of climate variables\n",
    "    for cols in [precip_cols, pressao_cols, temp_cols, umidade_cols, vento_cols]:\n",
    "        if cols:  # Check if list is not empty\n",
    "            df_clean[cols] = imputer.fit_transform(df_clean[cols])\n",
    "    \n",
    "    # Calculate yearly averages for each climate variable type\n",
    "    df_clean['avg_precip'] = df_clean[precip_cols].mean(axis=1)\n",
    "    df_clean['avg_pressao'] = df_clean[pressao_cols].mean(axis=1)\n",
    "    df_clean['avg_temp'] = df_clean[temp_cols].mean(axis=1)\n",
    "    df_clean['avg_umidade'] = df_clean[umidade_cols].mean(axis=1)\n",
    "    df_clean['avg_vento'] = df_clean[vento_cols].mean(axis=1)\n",
    "    \n",
    "    return df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_treatment_events(df):\n",
    "    \"\"\"\n",
    "    Identify all treatment events (when a region first receives treatment)\n",
    "    \"\"\"\n",
    "    treatment_events = []\n",
    "    \n",
    "    # Get all treated regions\n",
    "    treated_regions = df[df['treatment'] == 1]['id_microrregiao'].unique()\n",
    "    \n",
    "    for region in treated_regions:\n",
    "        region_data = df[df['id_microrregiao'] == region].sort_values('ano')\n",
    "        # Find first year of treatment\n",
    "        treatment_year = region_data[region_data['treatment'] == 1]['ano'].min()\n",
    "        \n",
    "        treatment_events.append({\n",
    "            'region': region,\n",
    "            'treatment_year': treatment_year\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(treatment_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_for_treatment_event(df, treated_region, treatment_year, features, caliper=0.2):\n",
    "    \"\"\"\n",
    "    Perform matching for a single treatment event\n",
    "    \"\"\"\n",
    "    # Get data up to treatment year\n",
    "    df_period = df[df['ano'] <= treatment_year].copy()\n",
    "    \n",
    "    # Create treatment indicator for this specific matching\n",
    "    df_period['current_treatment'] = ((df_period['id_microrregiao'] == treated_region) & \n",
    "                                    (df_period['ano'] == treatment_year)).astype(int)\n",
    "    \n",
    "    # Get potential controls (all observations from other regions before treatment year)\n",
    "    potential_controls = df_period[\n",
    "        (df_period['id_microrregiao'] != treated_region) & \n",
    "        (df_period['ano'] < treatment_year)\n",
    "    ]\n",
    "    \n",
    "    # Get treated observation\n",
    "    treated_obs = df_period[df_period['current_treatment'] == 1]\n",
    "    \n",
    "    if len(treated_obs) == 0 or len(potential_controls) == 0:\n",
    "        return None\n",
    "    \n",
    "    # Prepare data for propensity score calculation\n",
    "    matching_data = pd.concat([treated_obs, potential_controls])\n",
    "    \n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(matching_data[features])\n",
    "    \n",
    "    # Calculate propensity scores\n",
    "    model = LogisticRegression(random_state=42)\n",
    "    model.fit(X, matching_data['current_treatment'])\n",
    "    propensity_scores = model.predict_proba(X)[:, 1]\n",
    "    \n",
    "    # Add propensity scores to the data\n",
    "    matching_data['propensity_score'] = propensity_scores\n",
    "    \n",
    "    # Get treated unit's propensity score\n",
    "    treated_score = matching_data[matching_data['current_treatment'] == 1]['propensity_score'].iloc[0]\n",
    "    \n",
    "    # Calculate distances for all potential controls\n",
    "    potential_controls = matching_data[matching_data['current_treatment'] == 0].copy()\n",
    "    potential_controls['distance'] = abs(potential_controls['propensity_score'] - treated_score)\n",
    "    \n",
    "    # Apply caliper\n",
    "    caliper_threshold = caliper * np.std(matching_data['propensity_score'])\n",
    "    potential_controls = potential_controls[potential_controls['distance'] <= caliper_threshold]\n",
    "    \n",
    "    # Select matches (can select multiple controls per treated unit)\n",
    "    matches = potential_controls.nsmallest(n=5, columns='distance')  # Get top 5 matches\n",
    "    \n",
    "    # Combine treated and matched controls\n",
    "    matched_data = pd.concat([treated_obs, matches])\n",
    "    matched_data['treated_region'] = treated_region\n",
    "    matched_data['treatment_year'] = treatment_year\n",
    "    \n",
    "    return matched_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_dynamic_psm(df):\n",
    "    \"\"\"\n",
    "    Perform PSM analysis allowing for dynamic treatment timing and multiple control matches\n",
    "    \"\"\"\n",
    "    # Prepare data\n",
    "    df_clean = prepare_data_for_psm(df)\n",
    "    \n",
    "    # Get list of treatment events\n",
    "    treatment_events = get_treatment_events(df_clean)\n",
    "    \n",
    "    # Features for matching\n",
    "    features = [\n",
    "        'avg_precip', \n",
    "        'avg_pressao', \n",
    "        'avg_temp', \n",
    "        'avg_umidade', \n",
    "        'avg_vento'\n",
    "    ]\n",
    "    \n",
    "    # Perform matching for each treatment event\n",
    "    all_matches = []\n",
    "    \n",
    "    for _, event in treatment_events.iterrows():\n",
    "        matches = match_for_treatment_event(\n",
    "            df_clean,\n",
    "            event['region'],\n",
    "            event['treatment_year'],\n",
    "            features\n",
    "        )\n",
    "        \n",
    "        if matches is not None:\n",
    "            all_matches.append(matches)\n",
    "    \n",
    "    # Combine all matches\n",
    "    if all_matches:\n",
    "        matched_df = pd.concat(all_matches, ignore_index=True)\n",
    "        return matched_df\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_psm_matching(df):\n",
    "    \"\"\"\n",
    "    Perform PSM matching for DiD analysis\n",
    "    \"\"\"\n",
    "    # Prepare data\n",
    "    df_clean = prepare_data_for_psm(df)\n",
    "    \n",
    "    # Get list of treatment events\n",
    "    treatment_events = get_treatment_events(df_clean)\n",
    "    \n",
    "    # Features for matching\n",
    "    features = [\n",
    "        'avg_precip', \n",
    "        'avg_pressao', \n",
    "        'avg_temp', \n",
    "        'avg_umidade', \n",
    "        'avg_vento'\n",
    "    ]\n",
    "    \n",
    "    # Perform matching for each treatment event\n",
    "    all_matches = []\n",
    "    \n",
    "    for _, event in treatment_events.iterrows():\n",
    "        matches = match_for_treatment_event(\n",
    "            df_clean,\n",
    "            event['region'],\n",
    "            event['treatment_year'],\n",
    "            features\n",
    "        )\n",
    "        \n",
    "        if matches is not None:\n",
    "            all_matches.append(matches)\n",
    "    \n",
    "    # Combine all matches\n",
    "    if all_matches:\n",
    "        matched_df = pd.concat(all_matches, ignore_index=True)\n",
    "        \n",
    "        # Add matching information\n",
    "        matched_df['match_id'] = (matched_df['treated_region'].astype(str) + '_' + \n",
    "                                 matched_df['treatment_year'].astype(str))\n",
    "        \n",
    "        return matched_df\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matching Summary:\n",
      "Total treatment events analyzed: 370\n",
      "Average number of controls per treatment: 2.63\n",
      "Average treatment effect: -22328.08\n"
     ]
    }
   ],
   "source": [
    "# Read data\n",
    "df = pd.read_csv('../data/PAM_MET_pivoted.csv')\n",
    "\n",
    "# Perform dynamic PSM analysis\n",
    "matched_df = perform_dynamic_psm(df)\n",
    "\n",
    "if matched_df is not None:\n",
    "    # Calculate treatment effects\n",
    "    effects_df = calculate_treatment_effects(matched_df)\n",
    "    \n",
    "    print(\"\\nMatching Summary:\")\n",
    "    print(f\"Total treatment events analyzed: {len(effects_df)}\")\n",
    "    print(f\"Average number of controls per treatment: {effects_df['n_controls'].mean():.2f}\")\n",
    "    print(f\"Average treatment effect: {effects_df['effect'].mean():.2f}\")\n",
    "    \n",
    "    # Save results\n",
    "    matched_df.to_csv('matched_data.csv', index=False)\n",
    "    effects_df.to_csv('treatment_effects.csv', index=False)\n",
    "else:\n",
    "    print(\"No valid matches found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of matched pairs: 336\n",
      "Average production value (treated): 196766.20\n",
      "Average production value (control): 271633.04\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of matched pairs: {len(matched_df) // 2}\")\n",
    "print(f\"Average production value (treated): {treated_production:.2f}\")\n",
    "print(f\"Average production value (control): {control_production:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tcc-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
